import streamlit as st
import folium
from streamlit_folium import st_folium
import pandas as pd
import requests
from datetime import datetime
from streamlit_js_eval import streamlit_js_eval
from supabase import create_client, Client
from PIL import Image
import io
import re
import traceback
import os
import math
import time
import httpx

def run_with_retry(operation, description="Database operation", max_retries=3, delay=1):
    """
    Utility function to retry database operations on transient failures.
    """
    for i in range(max_retries):
        try:
            return operation().execute()
        except (httpx.RemoteProtocolError, httpx.ConnectError, httpx.ReadTimeout) as e:
            if i == max_retries - 1:
                st.error(f"‚ùå {description} ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏° {max_retries} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á: {str(e)}")
                raise e
            time.sleep(delay * (i + 1)) # Exponential-ish backoff
        except Exception as e:
            # For other errors, we might still want to retry if it's a connection issue disguised
            if "disconnect" in str(e).lower() or "timeout" in str(e).lower():
                if i == max_retries - 1: raise e
                time.sleep(delay * (i + 1))
            else:
                raise e

def haversine_distance(lat1, lon1, lat2, lon2):
    """
    Calculate the great circle distance between two points 
    on the earth (specified in decimal degrees) in meters.
    """
    # Convert decimal degrees to radians 
    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])

    # Haversine formula 
    dlon = lon2 - lon1 
    dlat = lat2 - lat1 
    a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2
    c = 2 * math.asin(math.sqrt(a)) 
    r = 6371000 # Radius of earth in meters
    return c * r

SUPABASE_URL = st.secrets["SUPABASE_URL"]
SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
SUPABASE_SERVICE_KEY = st.secrets["SUPABASE_SERVICE_KEY"]
WEATHER_API_KEY = st.secrets["WEATHER_API_KEY"]

try:
    # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô Supabase Clients
    supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
    supabase_storage = supabase
    supabase_db = supabase  # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ anon key ‡πÄ‡∏™‡∏°‡∏≠
    storage_configured = False
    db_configured = False

    if SUPABASE_SERVICE_KEY:
        try:
            supabase_admin: Client = create_client(SUPABASE_URL, SUPABASE_SERVICE_KEY)
            supabase_storage = supabase_admin 
            supabase_db = supabase_admin
            storage_configured = True
            db_configured = True
        except Exception as e:
            st.error(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏î‡πâ‡∏ß‡∏¢ Service Key ‡πÑ‡∏î‡πâ (‡∏à‡∏∞‡πÉ‡∏ä‡πâ Anon Key ‡πÅ‡∏ó‡∏ô): {str(e)}")
except Exception as e:
    st.error(f"‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Supabase ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {str(e)}")
    supabase = None
    supabase_storage = None
    supabase_db = None
    storage_configured = False
    db_configured = False

# --- 2. CACHED FUNCTIONS (‡∏´‡∏±‡∏ß‡πÉ‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß: ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏≥‡πÑ‡∏ß‡πâ) ---
@st.cache_data(ttl=3600)  # ‡∏à‡∏≥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ô‡πâ‡∏≥ 1 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á
def get_water_info(dam_name):
    try:
        if not dam_name:
            return "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πà‡∏≤‡∏á‡πÄ‡∏Å‡πá‡∏ö‡∏ô‡πâ‡∏≥"
        url = "https://api-v3.thaiwater.net/api/v1/thaiwater30/get_dam_daily"
        res = requests.get(url, timeout=5).json()
        if 'data' in res and 'dam' in res['data']:
            for dam in res['data']['dam']:
                if 'dam_name' in dam and 'th' in dam['dam_name'] and dam_name in dam['dam_name']['th']:
                    storage = dam.get('dam_storage_percent', 'N/A')
                    return f"‡∏ô‡πâ‡∏≥ {storage}% ({dam['dam_name']['th']})"
        return "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πà‡∏≤‡∏á‡πÄ‡∏Å‡πá‡∏ö‡∏ô‡πâ‡∏≥"
    except: return "‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡πâ‡∏≥‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ"

@st.cache_data(ttl=1800)  # ‡∏à‡∏≥‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏≠‡∏≤‡∏Å‡∏≤‡∏® 30 ‡∏ô‡∏≤‡∏ó‡∏µ
def get_full_weather(lat, lon):
    try:
        # 1. ‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ
        now_url = f"https://api.openweathermap.org/data/2.5/weather?lat={lat}&lon={lon}&appid={WEATHER_API_KEY}&units=metric&lang=th"
        c = requests.get(now_url, timeout=5).json()
        if 'main' in c and 'weather' in c and len(c['weather']) > 0:
            now_txt = f"{c['main']['temp']}¬∞C, {c['weather'][0]['description']}"
        else:
            now_txt = "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
        
        # 2. ‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤ (‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢ 3 ‡∏ä‡∏°. ‡∏°‡∏≤‡∏Ñ‡∏±‡∏î‡πÄ‡∏≠‡∏≤‡∏ß‡∏±‡∏ô‡∏•‡∏∞‡∏à‡∏∏‡∏î)
        fore_url = f"https://api.openweathermap.org/data/2.5/forecast?lat={lat}&lon={lon}&appid={WEATHER_API_KEY}&units=metric&lang=th"
        f = requests.get(fore_url, timeout=5).json()
        fore_list = []
        # ‡∏Ñ‡∏±‡∏î‡πÄ‡∏≠‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏∏‡∏Å‡πÜ 24 ‡∏ä‡∏°. (index 8, 16, 24)
        if 'list' in f and len(f['list']) > 0:
            for i in [8, 16, 24]:
                if i < len(f['list']):
                    day = f['list'][i]
                    if 'dt' in day and 'main' in day and 'weather' in day and len(day['weather']) > 0:
                        dt = datetime.fromtimestamp(day['dt']).strftime('%d/%m')
                        fore_list.append(f"‚Ä¢ {dt}: {day['main']['temp']:.0f}¬∞C, {day['weather'][0]['description']}")
        
        fore_html = "<br>".join(fore_list) if fore_list else "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤"
        return now_txt, fore_html
    except: return "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤"

@st.cache_data(ttl=600)
def load_spots():
    try:
        # ‡πÉ‡∏ä‡πâ supabase_db (‡∏ã‡∏∂‡πà‡∏á‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏ñ‡∏π‡∏Å override ‡πÄ‡∏õ‡πá‡∏ô admin client ‡πÅ‡∏•‡πâ‡∏ß)
        res = run_with_retry(lambda: supabase_db.table("spots").select("*"), "‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏∏‡∏î‡∏ï‡∏Å‡∏õ‡∏•‡∏≤")
        return pd.DataFrame(res.data)
    except Exception as e:
        st.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ: {str(e)}")
        return pd.DataFrame(columns=['name', 'lat', 'lon', 'fish_type', 'image_url', 'description'])

# --- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡∏´‡∏±‡∏ß‡πÉ‡∏à‡∏´‡∏•‡∏±‡∏Å) ---
def save_fishing_spot(name, fish_type, description, images_urls, lat, lon):
    if supabase_db is None:
        st.error("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ")
        return False

    try:
        # 1. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        res = run_with_retry(lambda: supabase_db.table("spots").select("*"), "‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏à‡∏∏‡∏î‡πÄ‡∏î‡∏¥‡∏°")
        df_existing = pd.DataFrame(res.data)
    
        match = None
        if not df_existing.empty:
            # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô ‡∏´‡∏£‡∏∑‡∏≠ ‡∏û‡∏¥‡∏Å‡∏±‡∏î‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏Å‡∏±‡∏ô (‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤ 100 ‡πÄ‡∏°‡∏ï‡∏£)
            # ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡πÄ‡∏ä‡πá‡∏Ñ‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ logic ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Å‡∏ß‡πà‡∏≤‡∏ñ‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏¢‡∏≠‡∏∞
            # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡πÄ‡∏ä‡πá‡∏Ñ‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡πÉ‡∏ô DataFrame
            
            # ‡∏Å‡∏£‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏ä‡∏∑‡πà‡∏≠‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß
            name_match = df_existing[df_existing['name'] == name]
            if not name_match.empty:
                match = name_match
            else:
                # ‡∏ñ‡πâ‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á ‡πÄ‡∏ä‡πá‡∏Ñ‡∏û‡∏¥‡∏Å‡∏±‡∏î‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á (100 ‡πÄ‡∏°‡∏ï‡∏£)
                def check_distance(row):
                    return haversine_distance(lat, lon, row['lat'], row['lon'])
                
                df_existing['distance'] = df_existing.apply(check_distance, axis=1)
                proximity_match = df_existing[df_existing['distance'] <= 100].copy() # ‡∏£‡∏±‡∏®‡∏°‡∏µ 100 ‡πÄ‡∏°‡∏ï‡∏£
                if not proximity_match.empty:
                    match = proximity_match.sort_values('distance')

        if match is not None and not match.empty:
            # --- ‡∏Å‡∏£‡∏ì‡∏µ‡∏°‡∏µ‡∏à‡∏∏‡∏î‡πÄ‡∏î‡∏¥‡∏°‡∏´‡∏£‡∏∑‡∏≠‡∏à‡∏∏‡∏î‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß: ‡πÉ‡∏´‡πâ "‡∏£‡∏ß‡∏°" ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ---
            target_row = match.iloc[0]
            
            old_fish = str(target_row.get('fish_type', ''))
            old_images = str(target_row.get('image_url', ''))
            old_desc = str(target_row.get('description', ''))

            # 1. ‡∏£‡∏ß‡∏°‡∏ä‡∏∑‡πà‡∏≠‡∏õ‡∏•‡∏≤ (‡πÄ‡∏≠‡∏≤‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥‡∏≠‡∏≠‡∏Å)
            new_fish_list = [f.strip() for f in (old_fish + "," + fish_type).split(",") if f.strip()]
            updated_fish = ", ".join(sorted(list(set(new_fish_list))))
            
            # 2. ‡∏£‡∏ß‡∏°‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û (‡πÄ‡∏≠‡∏≤‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥‡∏≠‡∏≠‡∏Å)
            new_img_str = ",".join(images_urls)
            old_img_list = [u.strip() for u in old_images.split(",") if u.strip()]
            new_img_list = [u.strip() for u in new_img_str.split(",") if u.strip()]
            updated_images = ",".join(list(dict.fromkeys(old_img_list + new_img_list)))

            # 3. ‡∏£‡∏ß‡∏°‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà ‡πÉ‡∏´‡πâ‡∏ï‡πà‡∏≠‡∏ó‡πâ‡∏≤‡∏¢)
            updated_desc = old_desc
            if description and description.strip() and description.strip() not in old_desc:
                timestamp = datetime.now().strftime('%d/%m/%Y %H:%M')
                separator = "\n" + "-"*20 + "\n" if old_desc else ""
                updated_desc = f"{old_desc}{separator}[{timestamp}] {description.strip()}"

            # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            update_data = {
                "fish_type": updated_fish,
                "image_url": updated_images,
                "description": updated_desc
            }
            
            # ‡πÉ‡∏ä‡πâ‡∏ä‡πà‡∏ß‡∏á‡∏û‡∏¥‡∏Å‡∏±‡∏î (Epsilon) ‡πÅ‡∏ó‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô‡πÄ‡∏õ‡πä‡∏∞‡πÜ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏®‡∏ô‡∏¥‡∏¢‡∏°‡∏Ñ‡∏•‡∏≤‡∏î‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô
            epsilon = 0.00001
            res_update = run_with_retry(
                lambda: supabase_db.table("spots").update(update_data)\
                    .eq("name", target_row['name'])\
                    .gte("lat", target_row['lat'] - epsilon)\
                    .lte("lat", target_row['lat'] + epsilon)\
                    .gte("lon", target_row['lon'] - epsilon)\
                    .lte("lon", target_row['lon'] + epsilon),
                "‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏∏‡∏î‡πÄ‡∏î‡∏¥‡∏°"
            )
                
            if res_update.data:
                dist_info = f" (‡∏´‡πà‡∏≤‡∏á {target_row['distance']:.1f} ‡∏°.)" if 'distance' in target_row else ""
                st.success(f"‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏à‡∏∏‡∏î‡πÄ‡∏î‡∏¥‡∏°: {target_row['name']}{dist_info} ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢! (‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡πÅ‡∏•‡πâ‡∏ß)")
                # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö
                with st.expander("‡∏î‡∏π‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à"):
                    st.write(res_update.data[0])
                return True
            else:
                st.warning("‚ö†Ô∏è ‡∏û‡∏ö‡∏à‡∏∏‡∏î‡πÄ‡∏î‡∏¥‡∏°‡πÉ‡∏ô‡πÅ‡∏≠‡∏õ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏‡πÅ‡∏ñ‡∏ß‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÑ‡∏î‡πâ (‡∏û‡∏¥‡∏Å‡∏±‡∏î‡πÉ‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡πÉ‡∏ô DB ‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô‡πÉ‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ó‡∏®‡∏ô‡∏¥‡∏¢‡∏°)")
                return False

        else:
            # --- ‡∏Å‡∏£‡∏ì‡∏µ‡πÄ‡∏õ‡πá‡∏ô‡∏à‡∏∏‡∏î‡πÉ‡∏´‡∏°‡πà: ‡πÉ‡∏´‡πâ "‡πÄ‡∏û‡∏¥‡πà‡∏°" ‡πÅ‡∏ñ‡∏ß‡πÉ‡∏´‡∏°‡πà ---
            res_insert = run_with_retry(
                lambda: supabase_db.table("spots").insert({
                    "name": name, "lat": lat, "lon": lon, 
                    "fish_type": fish_type, "description": description, "image_url": ",".join(images_urls)
                }),
                "‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏à‡∏∏‡∏î‡πÉ‡∏´‡∏°‡πà"
            )
            
            if res_insert.data:
                st.success("‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏à‡∏∏‡∏î‡∏ï‡∏Å‡∏õ‡∏•‡∏≤‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢!")
                with st.expander("‡∏î‡∏π‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÉ‡∏´‡∏°‡πà"):
                    st.write(res_insert.data[0])
                return True
            else:
                # ‡πÉ‡∏ô‡∏ö‡∏≤‡∏á‡∏Å‡∏£‡∏ì‡∏µ insert ‡∏≠‡∏≤‡∏à‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡πÄ‡∏ä‡πà‡∏ô RLS ‡∏´‡∏£‡∏∑‡∏≠ configuration)
                # ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÉ‡∏´‡πâ True ‡πÑ‡∏ß‡πâ‡∏Å‡πà‡∏≠‡∏ô‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ Exception
                st.info("‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå‡πÅ‡∏•‡πâ‡∏ß (‡∏£‡∏≠‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏≠‡∏≤‡∏ó‡∏¥‡∏ï‡∏¢‡πå‡∏ñ‡∏±‡∏î‡πÑ‡∏õ‡∏´‡∏≤‡∏Å‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏õ‡∏£‡∏≤‡∏Å‡∏è)")
                return True
    except Exception as e:
        st.error(f"Database Error: {str(e)}")
        st.code(traceback.format_exc())
        return False

# --- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏±‡∏ö‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏õ‡∏•‡∏≤ ---
def get_spot_fish_stats(fish_string):
    if not fish_string:
        return "‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏•‡∏≤"
    
    # ‡πÅ‡∏¢‡∏Å‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏õ‡∏•‡∏≤‡πÅ‡∏•‡∏∞‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô
    fish_list = [f.strip() for f in str(fish_string).split(",") if f.strip()]
    if not fish_list:
        return "‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏•‡∏≤"
    
    # ‡∏ô‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà
    from collections import Counter
    counts = Counter(fish_list)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÅ‡∏ö‡∏ö‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î
    stat_text = "<br>".join([f"‚Ä¢ {fish}: {count} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á" for fish, count in counts.items()])
    return stat_text

# --- 3. SESSION STATE ---
st.set_page_config(page_title="Thai Fishing Pro", layout="wide")

if 'v_lat' not in st.session_state: st.session_state.v_lat = 13.7563
if 'v_lon' not in st.session_state: st.session_state.v_lon = 100.5018

# GPS ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á (‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏á)
gps_raw = streamlit_js_eval(
    js_expressions="new Promise((r) => {navigator.geolocation.getCurrentPosition((p) => r({lat: p.coords.latitude, lon: p.coords.longitude}), (e) => r(null), {enableHighAccuracy: true})})",
    key='gps_engine_v13'
)

# --- 4. SIDEBAR ---
st.sidebar.title("üé£ Fishing Pro")

# ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
st.sidebar.info(f"üìç ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô:\n{st.session_state.v_lat:.4f}, {st.session_state.v_lon:.4f}")

if st.sidebar.button("üéØ ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô"):
    if gps_raw and 'lat' in gps_raw and 'lon' in gps_raw:
        st.session_state.v_lat = gps_raw['lat']
        st.session_state.v_lon = gps_raw['lon']
        st.success(f"‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á: {gps_raw['lat']:.4f}, {gps_raw['lon']:.4f}")
        st.rerun()
    else:
        st.warning("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏∂‡∏á‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á GPS ‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÉ‡∏ô‡πÄ‡∏ö‡∏£‡∏≤‡∏ß‡πå‡πÄ‡∏ã‡∏≠‡∏£‡πå ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô")

# ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏õ‡πâ‡∏≠‡∏ô‡∏û‡∏¥‡∏Å‡∏±‡∏î‡πÄ‡∏≠‡∏á
with st.sidebar.expander("üìç ‡∏õ‡πâ‡∏≠‡∏ô‡∏û‡∏¥‡∏Å‡∏±‡∏î‡πÄ‡∏≠‡∏á"):
    manual_lat = st.number_input("‡∏•‡∏∞‡∏ï‡∏¥‡∏à‡∏π‡∏î (Latitude)", value=st.session_state.v_lat, format="%.6f")
    manual_lon = st.number_input("‡∏•‡∏≠‡∏á‡∏à‡∏¥‡∏à‡∏π‡∏î (Longitude)", value=st.session_state.v_lon, format="%.6f")
    if st.button("‚úÖ ‡πÉ‡∏ä‡πâ‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏ô‡∏µ‡πâ"):
        st.session_state.v_lat = manual_lat
        st.session_state.v_lon = manual_lon
        st.success(f"‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏û‡∏¥‡∏Å‡∏±‡∏î: {manual_lat:.4f}, {manual_lon:.4f}")
        st.rerun()

all_data = load_spots()

with st.sidebar.form("add_spot_form", clear_on_submit=True):
    st.subheader("‚ûï ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏Å‡∏õ‡∏•‡∏≤")
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
    gps_status = "‚úÖ GPS" if (gps_raw and 'lat' in gps_raw) else "üìç ‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô"
    st.caption(f"{gps_status}: {st.session_state.v_lat:.4f}, {st.session_state.v_lon:.4f}")
    
    name = st.text_input("‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏°‡∏≤‡∏¢ (‡πÉ‡∏™‡πà‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏Ç‡∏∑‡πà‡∏≠‡∏ô/‡∏≠‡πà‡∏≤‡∏á‡πÄ‡∏Å‡πá‡∏ö‡∏ô‡πâ‡∏≥‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏∂‡∏á‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ô‡πâ‡∏≥)", key="spot_name")
    fish = st.text_input("‡∏õ‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö", key="spot_fish")
    description = st.text_input("‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î", key="spot_desc")
    files = st.file_uploader("‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û", type=['jpg','png','jpeg'], accept_multiple_files=True, key="spot_images")

    if st.form_submit_button("‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", use_container_width=True):
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏∏‡∏î‡∏ï‡∏Å‡∏õ‡∏•‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        if not name or not name.strip():
            st.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏∏‡∏î‡∏ï‡∏Å‡∏õ‡∏•‡∏≤")
        else:
            try:
                # ‡πÉ‡∏ä‡πâ GPS ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ ‡πÑ‡∏°‡πà‡πÄ‡∏ä‡πà‡∏ô‡∏ô‡∏±‡πâ‡∏ô‡πÉ‡∏ä‡πâ session state
                use_lat = gps_raw['lat'] if gps_raw and 'lat' in gps_raw else st.session_state.v_lat
                use_lon = gps_raw['lon'] if gps_raw and 'lon' in gps_raw else st.session_state.v_lon
                
                urls = []
                if files:
                    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ supabase_storage ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                    if 'supabase_storage' not in globals() or supabase_storage is None:
                        st.error("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Supabase Storage ‡πÑ‡∏î‡πâ")
                        st.warning("‡∏à‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û")
                    elif not storage_configured:
                        st.warning("‚ö†Ô∏è ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ SUPABASE_SERVICE_KEY - ‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏à‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß")
                    
                    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÑ‡∏ü‡∏•‡πå
                    total_files = len(files)
                    progress_bar = st.progress(0)
                    status_text = st.empty()

                    
                    for idx, f in enumerate(files):
                        try:
                            status_text.text(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ {idx + 1}/{total_files}: {f.name}")
                                
                            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå (‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏ó‡∏µ‡πà 10MB)
                            if f.size > 10 * 1024 * 1024:
                                st.warning(f"‡πÑ‡∏ü‡∏•‡πå {f.name} ‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ (‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 10MB) ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏¢‡πà‡∏≠‡∏Ç‡∏ô‡∏≤‡∏î‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥")
                                
                            # ‡∏≠‡πà‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
                            img = Image.open(f).convert("RGB")
                            img.thumbnail((800, 800), Image.Resampling.LANCZOS)
                                
                            # ‡∏™‡∏£‡πâ‡∏≤‡∏á buffer ‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏π‡∏õ
                            buf = io.BytesIO()
                            img.save(buf, format='JPEG', quality=85)
                            buf.seek(0)  # Reset buffer position
                                
                            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢
                            safe_name = re.sub(r'[^a-zA-Z0-9._-]', '_', f.name)
                            timestamp = datetime.now().strftime('%Y%m%d%H%M%S_%f')
                            fname = f"{timestamp}_{safe_name}"
                                
                            # ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏õ‡∏¢‡∏±‡∏á Supabase Storage (‡πÉ‡∏ä‡πâ supabase_storage ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå bypass RLS)
                            upload_result = supabase_storage.storage.from_("fishing_images").upload(
                                fname, 
                                buf.getvalue(),
                                file_options={"content-type": "image/jpeg", "upsert": "true"}
                            )
                                
                            # ‡∏î‡∏∂‡∏á public URL
                            public_url = supabase_storage.storage.from_("fishing_images").get_public_url(fname)
                            # ‡πÅ‡∏õ‡∏•‡∏á http ‡πÄ‡∏õ‡πá‡∏ô https
                            if public_url.startswith("http://"):
                                public_url = public_url.replace("http://", "https://")
                                
                            urls.append(public_url)
                                
                            # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï progress
                            progress_bar.progress((idx + 1) / total_files)
                                
                        except Exception as e:
                            error_msg = str(e)
                            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô RLS error ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                            if "row-level security policy" in error_msg.lower() or "unauthorized" in error_msg.lower():
                                st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ {f.name} ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å Row Level Security (RLS)")
                                
                            else:
                                st.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ {f.name}: {error_msg}")
                            with st.expander(f"‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î - {f.name}"):
                                st.code(traceback.format_exc())

                    # ‡∏•‡∏ö progress bar ‡πÅ‡∏•‡∏∞ status text
                    progress_bar.empty()
                    status_text.empty()
                        
                    if urls:
                        st.success(f"‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û {len(urls)}/{total_files} ‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
                
                
                        
            except Exception as e:
                    error_msg = str(e)
                    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô RLS error ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                    if "row-level security policy" in error_msg.lower() or "42501" in error_msg:
                        st.error("‚ùå ‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å Row Level Security (RLS)")
                       
                    else:
                        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {error_msg}")
                    with st.expander("‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î"):
                        st.code(traceback.format_exc())
        
        if save_fishing_spot(name, fish, description, urls, use_lat, use_lon):
            st.cache_data.clear()
            st.rerun()

# --- 5. STABLE MAP DISPLAY ---
st.subheader("üó∫Ô∏è ‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏ï‡∏Å‡∏õ‡∏•‡∏≤")

@st.fragment
def render_fishing_map(df):
    m = folium.Map(location=[st.session_state.v_lat, st.session_state.v_lon], zoom_start=12)

    # ‡∏´‡∏°‡∏∏‡∏î‡∏Ñ‡∏∏‡∏ì - ‡πÉ‡∏ä‡πâ GPS ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ ‡πÑ‡∏°‡πà‡πÄ‡∏ä‡πà‡∏ô‡∏ô‡∏±‡πâ‡∏ô‡πÉ‡∏ä‡πâ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏à‡∏≤‡∏Å session state
    user_lat = gps_raw['lat'] if gps_raw and 'lat' in gps_raw else st.session_state.v_lat
    user_lon = gps_raw['lon'] if gps_raw and 'lon' in gps_raw else st.session_state.v_lon
    folium.Marker(
        [user_lat, user_lon], 
        icon=folium.Icon(color='red', icon='user', prefix='fa'),
        tooltip="‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì"
    ).add_to(m)

    for _, row in df.iterrows():

        spot_stats = get_spot_fish_stats(row['fish_type'])

        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà Cache ‡πÑ‡∏ß‡πâ (‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏∞‡∏û‡∏£‡∏¥‡∏ö)
        weather_now, weather_fore = get_full_weather(row['lat'], row['lon'])
        water_lv = get_water_info(row['name'])
        
        # ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û (‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏ô‡∏¥‡πâ‡∏ß)
        images = []
        if "image_url" in row and row["image_url"]:
            try:
                images = [u.strip() for u in str(row["image_url"]).split(",") if u.strip()]
            except:
                images = []
        img_html = ""
        if images:
            img_html = '<div style="display: flex; overflow-x: auto; gap: 5px; width: 220px; background:#f0f0f0; border-radius:8px; padding:5px;">'
            for u in images:
                img_html += f'<img src="{u}" style="height: 120px; border-radius: 5px; flex-shrink: 0;">'
            img_html += '</div>'

        name = row.get('name', '‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠')
        fish_type = row.get('fish_type', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')
        description = row.get('description', '‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î')
        
        popup_html = f"""
        <div style='width: 220px; font-family: sans-serif;'>
            {img_html}
            <h4 style='margin: 8px 0 2px 0; color: #1a73e8;'>{name}</h4>
            <b>üêü ‡∏õ‡∏•‡∏≤:</b> {fish_type}<br>
            <div style='background: #e8f0fe; padding: 8px; border-radius: 5px; margin-top: 5px;'>
                <b>üìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÄ‡∏à‡∏≠‡∏õ‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà:</b><br>
                <small>{spot_stats}</small>
            </div>
            <b>‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î:</b> {description}<br>
            <b>üå°Ô∏è ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ:</b> {weather_now}<br>
            <b>üíß ‡∏ô‡πâ‡∏≥:</b> {water_lv}
            <hr style='margin: 5px 0;'>
            <small><b>üìÖ ‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå 3 ‡∏ß‡∏±‡∏ô:</b><br>{weather_fore}</small>
            <a href="https://www.google.com/maps/dir/?api=1&destination={row['lat']},{row['lon']}" target="_blank">
                <button style='width:100%; background:#4285F4; color:white; border:none; padding:10px; border-radius:5px; margin-top:10px; cursor:pointer; font-weight:bold;'>üöÄ ‡∏ô‡∏≥‡∏ó‡∏≤‡∏á</button>
            </a>
        </div>
        """
        folium.Marker(
            [row['lat'], row['lon']],
            popup=folium.Popup(popup_html, max_width=250),
            icon=folium.Icon(color='green', icon='fish', prefix='fa')
        ).add_to(m)

    #returned_objects=[] ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏¥‡πà‡∏á‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
    st_folium(m, width="100%", height=550, key="stable_fishing_map", returned_objects=[])

render_fishing_map(all_data)
st.button("üîÑ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà (Clear Cache)", on_click=st.cache_data.clear)

# --- 5.5 DATA PREVIEW (DEBUG) ---
with st.expander("üîç ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Debug)"):
    if not all_data.empty:
        st.write("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÅ‡∏≠‡∏õ‡∏î‡∏∂‡∏á‡∏°‡∏≤‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ:")
        st.dataframe(all_data, use_container_width=True)
    else:
        st.info("‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤ (‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏≠‡∏õ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢ RLS)")

# --- 6. SPOT MANAGEMENT ---
st.divider()
st.subheader("üìã ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏à‡∏∏‡∏î‡∏ï‡∏Å‡∏õ‡∏•‡∏≤")

# Filter and search
col1, col2, col3 = st.columns(3)
with col1:
    search_term = st.text_input("üîç ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏à‡∏∏‡∏î‡∏ï‡∏Å‡∏õ‡∏•‡∏≤", placeholder="‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏∏‡∏î, ‡∏õ‡∏•‡∏≤, ‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î")
with col2:
    fish_filter = st.selectbox("üêü ‡∏Å‡∏£‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏õ‡∏•‡∏≤", ["‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"] + sorted(all_data['fish_type'].dropna().unique().tolist()) if not all_data.empty else ["‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"])
with col3:
    sort_option = st.selectbox("üìä ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°", ["‡∏ä‡∏∑‡πà‡∏≠ (A-Z)", "‡∏ä‡∏∑‡πà‡∏≠ (Z-A)", "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î"])

# Filter data
filtered_data = all_data.copy()
if not all_data.empty:
    if search_term:
        mask = (
            filtered_data['name'].str.contains(search_term, case=False, na=False) |
            filtered_data['fish_type'].str.contains(search_term, case=False, na=False) |
            filtered_data['description'].str.contains(search_term, case=False, na=False)
        )
        filtered_data = filtered_data[mask]
    
    if fish_filter != "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î":
        filtered_data = filtered_data[filtered_data['fish_type'] == fish_filter]
    
    # Sort data
    if sort_option == "‡∏ä‡∏∑‡πà‡∏≠ (A-Z)":
        filtered_data = filtered_data.sort_values('name')
    elif sort_option == "‡∏ä‡∏∑‡πà‡∏≠ (Z-A)":
        filtered_data = filtered_data.sort_values('name', ascending=False)

# Display filtered spots
if not filtered_data.empty:
    st.write(f"**‡∏û‡∏ö {len(filtered_data)} ‡∏à‡∏∏‡∏î‡∏ï‡∏Å‡∏õ‡∏•‡∏≤**")
    
    # Display spots in expandable sections
    for i, (idx, row) in enumerate(filtered_data.iterrows()):
        spot_id = row.get('id', idx) if 'id' in row else f"{row.get('lat', '')}_{row.get('lon', '')}_{row.get('name', '')}"
        with st.expander(f"üé£ {row.get('name', '‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠')} - {row.get('fish_type', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')}"):
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.write(f"**‡∏û‡∏¥‡∏Å‡∏±‡∏î:** {row.get('lat', 'N/A')}, {row.get('lon', 'N/A')}")
                st.write(f"**‡∏õ‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö:** {row.get('fish_type', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')}")
                st.write(f"**‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î:** {row.get('description', '‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î')}")
                
                # Display images if available
                images = []
                if "image_url" in row and row["image_url"]:
                    try:
                        images = [u.strip() for u in str(row["image_url"]).split(",") if u.strip()]
                    except:
                        images = []
                
                if images:
                    st.write("**‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û:**")
                    cols = st.columns(min(len(images), 3))
                    for j, img_url in enumerate(images[:3]):
                        with cols[j % 3]:
                            st.image(img_url, use_container_width=True)
            
            with col2:
                # Action buttons
                if st.button("üó∫Ô∏è ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ô‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà", key=f"map_{i}_{spot_id}"):
                    st.session_state.v_lat = row['lat']
                    st.session_state.v_lon = row['lon']
                    st.rerun()
                
                # Weather info
                try:
                    weather_now, weather_fore = get_full_weather(row['lat'], row['lon'])
                    st.write(f"**üå°Ô∏è ‡∏≠‡∏≤‡∏Å‡∏≤‡∏®:** {weather_now}")
                except:
                    st.write("**üå°Ô∏è ‡∏≠‡∏≤‡∏Å‡∏≤‡∏®:** ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
                
                # Water level info
                water_info = get_water_info(row.get('name', ''))
                st.write(f"**üíß ‡∏ô‡πâ‡∏≥:** {water_info}")
else:
    st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏à‡∏∏‡∏î‡∏ï‡∏Å‡∏õ‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤")

# --- 7. STATISTICS ---
st.divider()
st.subheader("üìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥")

if not all_data.empty:
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("üé£ ‡∏à‡∏∏‡∏î‡∏ï‡∏Å‡∏õ‡∏•‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", len(all_data))
    
    with col2:
        unique_fish = all_data['fish_type'].dropna().nunique()
        st.metric("üêü ‡∏ä‡∏ô‡∏¥‡∏î‡∏õ‡∏•‡∏≤", unique_fish)
    
    with col3:
        total_images = sum(
            len(str(row.get('image_url', '')).split(',')) 
            if row.get('image_url') else 0 
            for _, row in all_data.iterrows()
        )
        st.metric("üì∑ ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", total_images)
    
    with col4:
        spots_with_images = sum(
            1 for _, row in all_data.iterrows() 
            if row.get('image_url') and str(row.get('image_url', '')).strip()
        )
        st.metric("üì∏ ‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û", spots_with_images)
    
    # Fish type distribution
    if 'fish_type' in all_data.columns:
        st.write("**üêü ‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏ä‡∏ô‡∏¥‡∏î‡∏õ‡∏•‡∏≤:**")
        fish_counts = all_data['fish_type'].value_counts()
        st.bar_chart(fish_counts)
    
    # Map coverage
    if 'lat' in all_data.columns and 'lon' in all_data.columns:
        st.write("**üìç ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°:**")
        try:
            min_lat, max_lat = all_data['lat'].min(), all_data['lat'].max()
            min_lon, max_lon = all_data['lon'].min(), all_data['lon'].max()
            center_lat = (min_lat + max_lat) / 2
            center_lon = (min_lon + max_lon) / 2
            
            st.write(f"**‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏Å‡∏•‡∏≤‡∏á:** {center_lat:.4f}, {center_lon:.4f}")
            st.write(f"**‡∏ä‡πà‡∏ß‡∏á‡∏•‡∏∞‡∏ï‡∏¥‡∏à‡∏π‡∏î:** {min_lat:.4f} ‡∏ñ‡∏∂‡∏á {max_lat:.4f}")
            st.write(f"**‡∏ä‡πà‡∏ß‡∏á‡∏•‡∏≠‡∏á‡∏à‡∏¥‡∏à‡∏π‡∏î:** {min_lon:.4f} ‡∏ñ‡∏∂‡∏á {max_lon:.4f}")
        except:
            st.write("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡πÑ‡∏î‡πâ")

# --- 8. EXPORT FUNCTIONALITY ---
st.divider()
st.subheader("üíæ ‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")

col1, col2 = st.columns(2)

with col1:
    if st.button("üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î CSV"):
        if not all_data.empty:
            csv = all_data.to_csv(index=False).encode('utf-8-sig')
            st.download_button(
                label="‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå CSV",
                data=csv,
                file_name=f"fishing_spots_{datetime.now().strftime('%Y%m%d')}.csv",
                mime="text/csv"
            )
        else:
            st.warning("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å")

with col2:
    if st.button("üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î JSON"):
        if not all_data.empty:
            json_data = all_data.to_json(orient='records', force_ascii=False, indent=2)
            st.download_button(
                label="‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå JSON",
                data=json_data.encode('utf-8'),
                file_name=f"fishing_spots_{datetime.now().strftime('%Y%m%d')}.json",
                mime="application/json"
            )
        else:
            st.warning("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å")

# --- 9. FOOTER ---
st.divider()
st.markdown("""
<div style='text-align: center; color: #666; padding: 20px;'>
    <p>üé£ <strong>Thai Fishing Pro</strong> - ‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ô‡∏±‡∏Å‡∏ï‡∏Å‡∏õ‡∏•‡∏≤</p>
    <p>‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏î‡πâ‡∏ß‡∏¢ Streamlit, Folium, ‡πÅ‡∏•‡∏∞ Supabase</p>
</div>
""", unsafe_allow_html=True)
